{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/armiro/Covid19-Detection/blob/master/hands_on_covid_cxnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ig7Bd5HNTYdC"
   },
   "source": [
    "# Up and running with COVID-CXNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3lTao6TBTrSF"
   },
   "source": [
    "## Retraining/ fine-tuning CheXNet model on COVID-19 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ep8uoYgw9yy0"
   },
   "outputs": [],
   "source": [
    "import glob, numpy as np, cv2, matplotlib.pyplot as plt, tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras import Model, callbacks as cb, optimizers\n",
    "from tensorflow.keras.models import load_model, model_from_json\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, Input, concatenate\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from skimage.filters import rank\n",
    "from skimage.morphology import disk\n",
    "\n",
    "from BEASF import BEASF\n",
    "from visualization_tools import GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "jbENt9hwi5GO",
    "outputId": "1f65cd89-3ae4-4e22-c843-3660966e5d76"
   },
   "outputs": [],
   "source": [
    "X = np.load(file='/content/drive/My Drive/Datasets/covid_cxr_dataset/cxr_samples.npy')\n",
    "y = np.load(file='/content/drive/My Drive/Datasets/covid_cxr_dataset/cxr_labels.npy')\n",
    "X = X[:500]\n",
    "y = y[:500]\n",
    "\n",
    "# X = np.concatenate((X, X, X), axis=-1)\n",
    "# X = np.array([X[idx] / 255. for idx in range(len(X))])\n",
    "\n",
    "print('number of total dataset images:', len(X))\n",
    "print('number of total dataset labels:', len(y))\n",
    "print('dataset shape:', X.shape)\n",
    "\n",
    "rnd_idx = np.random.choice(a=len(X), size=None)\n",
    "plt.imshow(X=X[rnd_idx].squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(label='a random image from the dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ibEjL5_WjCxE",
    "outputId": "922d85a1-c2b2-40a3-f5f8-f8f63412f695"
   },
   "outputs": [],
   "source": [
    "def unet(input_size=(256,256,1)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    return Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "segmentor = unet(input_size=(320, 320, 1))\n",
    "segmentor.summary()\n",
    "segmentor.load_weights('/content/drive/My Drive/cxr_reg_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0KoRXwgjn1B"
   },
   "outputs": [],
   "source": [
    "def do_segmentation(images, disk_rad=40, kernel_size=(5, 5), num_iter=3, margin=0):\n",
    "    equ_images = [rank.equalize(image.squeeze(), selem=disk(radius=disk_rad)) for image in images]\n",
    "    masks = [segmentor(np.expand_dims(equ_image, axis=[0, -1])) for equ_image in equ_images]\n",
    "    masks = [cv2.dilate(np.squeeze(mask), kernel=np.ones(kernel_size), iterations=num_iter) for mask in masks]\n",
    "    images = [image[np.min(np.where(masks[idx]==1)[0]) - margin:np.max(np.where(masks[idx]==1)[0]) + margin, \n",
    "                    np.min(np.where(masks[idx]==1)[1]) - margin:np.max(np.where(masks[idx]==1)[1]) + margin]\n",
    "              for idx, image in enumerate(images)]\n",
    "    images = [cv2.resize(image, dsize=(320, 320), interpolation=cv2.INTER_CUBIC) for image in images]\n",
    "    images = [np.expand_dims(image, axis=-1) for image in images]\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFYdPnaar0Pb"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_segmented = do_segmentation(images=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "R1EeVVDK-b_G",
    "outputId": "96088134-2c77-4ec6-8e04-dd9141fa26e8"
   },
   "outputs": [],
   "source": [
    "X = X_segmented[:3628]\n",
    "y = y[:3628]\n",
    "\n",
    "num_covid_samples = 0\n",
    "num_normal_samples = 0\n",
    "for idx, img in enumerate(X):\n",
    "  if y[idx]:\n",
    "    num_covid_samples += 1\n",
    "  else:\n",
    "    num_normal_samples += 1\n",
    "print('num carious images:', num_covid_samples)\n",
    "print('num healthy images:', num_normal_samples)\n",
    "\n",
    "\n",
    "# manual label smoothing by 0.1 deviation\n",
    "# y[np.where(y == 0)] = 0.1\n",
    "# y[np.where(y == 1)] = 0.9\n",
    "\n",
    "# apply image enhancements and concat with the original image\n",
    "X_beasf = np.array([BEASF(image=image, gamma=1.5) for image in X])\n",
    "X_clahe = np.array([cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(image) for image in X])\n",
    "X_clahe = np.array([np.expand_dims(a=image, axis=-1) for image in X_clahe])\n",
    "X = np.concatenate((X_beasf, X_clahe, X), axis=-1)\n",
    "\n",
    "X = np.array([X[idx] / 255. for idx in range(len(X))])\n",
    "\n",
    "print('number of total dataset images:', len(X))\n",
    "print('number of total dataset labels:', len(y))\n",
    "print('dataset shape:', X.shape)\n",
    "\n",
    "rnd_idx = np.random.choice(a=len(X), size=None)\n",
    "plt.imshow(X=X[rnd_idx].squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(label='a random image from the dataset')\n",
    "plt.show()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=18)\n",
    "\n",
    "# # NOTE: sklearn train_test_split function copies the dataset, hence deleting initial data\n",
    "# # variables will increase RAM space drastically (~ x2)\n",
    "del X, X_segmented, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rbGpi2wS_WZA"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: applying zoom and brightness at the same time will change image pixel range from\n",
    "# [0, 1] to [0, 255], hence we need to add rescaling again (despite doing it when importing\n",
    "# dataset). Otherwise, model will see all validation data (not undergone augmentation) as \n",
    "# black images giving a same prediction value for all\n",
    "augmenter = ImageDataGenerator(rotation_range=170, horizontal_flip=True, vertical_flip=True, \n",
    "                               zoom_range=[0.8, 1.5], brightness_range=[0.5, 1.3], rescale=1./255,\n",
    "                               width_shift_range=0.2, height_shift_range=0.2, fill_mode='constant')\n",
    "\n",
    "# NOTE: Keras ImageDataGenerator does not keep input image default ratio (as of v2.3.1)\n",
    "# NOTE: Keras ImageDataGenerator does not resize-and-padd when doing rotation (thus \n",
    "# loosing part of the image due to cropping while rotating)\n",
    "checkpoint = cb.ModelCheckpoint('/content/drive/My Drive/covid_model/eps={epoch:03d}_valLoss={val_loss:.4f}.hdf5',\n",
    "                                monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "cb_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "N3c2qTbc_wqi",
    "outputId": "abb17642-b3e1-4735-ecb6-57a2b5d4687a"
   },
   "outputs": [],
   "source": [
    "backbone = load_model(\"/content/drive/My Drive/CheXNet_model.hdf5\")\n",
    "fc = Dense(units=10, activation='relu', name='fc')(backbone.layers[-2].output)\n",
    "do = Dropout(rate=0.2, name='dropout')(fc)\n",
    "output = Dense(units=1, activation='sigmoid', name='pred')(do)\n",
    "classifier = Model(inputs=backbone.input, outputs=output)\n",
    "# for layer in classifier.layers[:-1]:\n",
    "#     layer.trainable = False\n",
    "fast_adam = optimizers.Adam(learning_rate=0.001)\n",
    "smoothened_bce = tf.losses.BinaryCrossentropy(label_smoothing=0.1)\n",
    "classifier.compile(optimizer=fast_adam, loss=smoothened_bce, metrics=['accuracy'])\n",
    "# classifier.summary()\n",
    "print('number of pretrained network layers:', len(classifier.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "GRY6AE_nWQZF",
    "outputId": "5484d338-d41c-4c8c-eadf-eba32144b680"
   },
   "outputs": [],
   "source": [
    "# test CheXNet accuracy and imaging features on sample cases\n",
    "predictor = load_model('/content/drive/My Drive/CheXNet_model.hdf5')\n",
    "IMG_ID = np.random.randint(low=0, high=len(X), size=None)\n",
    "print('image index:', IMG_ID)\n",
    "test_img = X[IMG_ID]\n",
    "temp_img = (X[IMG_ID] * 255.).astype('uint8')\n",
    "\n",
    "fig1 = plt.figure(num=7, figsize=(21, 3))\n",
    "\n",
    "cam = GradCAM(model=predictor, classIdx=0, layerName=None)\n",
    "heatmap = cam.compute_heatmap(image=test_img, normalize=True)\n",
    "overlaid_heatmap = cam.overlay_heatmap(heatmap=heatmap, image=temp_img, alpha=0.8, \n",
    "                                       colormap=cv2.COLORMAP_HSV)\n",
    "plt.subplot(1, 7, 1)\n",
    "plt.imshow(overlaid_heatmap)\n",
    "plt.axis('off')\n",
    "plt.title('atelectasis=%.4f' % predictor.predict(np.expand_dims(test_img, axis=0))[0][0])\n",
    "\n",
    "cam = GradCAM(model=predictor, classIdx=3, layerName=None)\n",
    "heatmap = cam.compute_heatmap(image=test_img, normalize=True)\n",
    "overlaid_heatmap = cam.overlay_heatmap(heatmap=heatmap, image=temp_img, alpha=0.8, \n",
    "                                       colormap=cv2.COLORMAP_HSV)\n",
    "plt.subplot(1, 7, 2)\n",
    "plt.imshow(overlaid_heatmap, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('infiltration=%.4f' % predictor.predict(np.expand_dims(test_img, axis=0))[0][3])\n",
    "\n",
    "cam = GradCAM(model=predictor, classIdx=4, layerName=None)\n",
    "heatmap = cam.compute_heatmap(image=test_img, normalize=True)\n",
    "overlaid_heatmap = cam.overlay_heatmap(heatmap=heatmap, image=temp_img, alpha=0.8, \n",
    "                                       colormap=cv2.COLORMAP_HSV)\n",
    "plt.subplot(1, 7, 3)\n",
    "plt.imshow(overlaid_heatmap, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('mass=%.4f' % predictor.predict(np.expand_dims(test_img, axis=0))[0][4])\n",
    "\n",
    "cam = GradCAM(model=predictor, classIdx=5, layerName=None)\n",
    "heatmap = cam.compute_heatmap(image=test_img, normalize=True)\n",
    "overlaid_heatmap = cam.overlay_heatmap(heatmap=heatmap, image=temp_img, alpha=0.8, \n",
    "                                       colormap=cv2.COLORMAP_HSV)\n",
    "plt.subplot(1, 7, 4)\n",
    "plt.imshow(overlaid_heatmap, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('nodule=%.4f' % predictor.predict(np.expand_dims(test_img, axis=0))[0][5])\n",
    "\n",
    "cam = GradCAM(model=predictor, classIdx=6, layerName=None)\n",
    "heatmap = cam.compute_heatmap(image=test_img, normalize=True)\n",
    "overlaid_heatmap = cam.overlay_heatmap(heatmap=heatmap, image=temp_img, alpha=0.8, \n",
    "                                       colormap=cv2.COLORMAP_HSV)\n",
    "plt.subplot(1, 7, 5)\n",
    "plt.imshow(overlaid_heatmap, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('pneumonia=%.4f' % predictor.predict(np.expand_dims(test_img, axis=0))[0][6])\n",
    "\n",
    "cam = GradCAM(model=predictor, classIdx=8, layerName=None)\n",
    "heatmap = cam.compute_heatmap(image=test_img, normalize=True)\n",
    "overlaid_heatmap = cam.overlay_heatmap(heatmap=heatmap, image=temp_img, alpha=0.8, \n",
    "                                       colormap=cv2.COLORMAP_HSV)\n",
    "plt.subplot(1, 7, 6)\n",
    "plt.imshow(overlaid_heatmap, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('consolidation=%.4f' % predictor.predict(np.expand_dims(test_img, axis=0))[0][8])\n",
    "\n",
    "plt.subplot(1, 7, 7)\n",
    "plt.imshow(test_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('label=%d' % y[IMG_ID])\n",
    "\n",
    "plt.show()\n",
    "print('all classes probabilities:')\n",
    "print(predictor.predict(np.expand_dims(test_img, axis=0))[0])\n",
    "# fig1.savefig(fname='/content/drive/My Drive/chexnet_ex.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1XyjExIGCFA"
   },
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', \n",
    "                                                  classes=np.unique(y_train), y=y_train)\n",
    "print('class weights are:', class_weights)\n",
    "fine_tuning = classifier.fit(augmenter.flow(x=X_train, y=y_train, batch_size=16), \n",
    "                             steps_per_epoch=len(X_train)//16,\n",
    "                             callbacks=cb_list, epochs=20, verbose=1, \n",
    "                             validation_data=(X_test, y_test),\n",
    "                             class_weight=dict({0: class_weights[0], 1: class_weights[1]}))\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fine_tuning.history['loss'], color='r', label='training_loss')\n",
    "plt.plot(fine_tuning.history['val_loss'], color='g', label='validation_loss')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(fine_tuning.history['accuracy'], color='r', label='training_accuracy')\n",
    "plt.plot(fine_tuning.history['val_accuracy'], color='g', label='validation_accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# fig.savefig('/content/drive/My Drive/covid_model/fine_tuning.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8fKqbZ1XBNG"
   },
   "outputs": [],
   "source": [
    "classifier.load_weights('/content/drive/My Drive/covid_model/eps=?_valLoss=?.hdf5')\n",
    "y_pred = classifier.predict(X_test)\n",
    "print('number of test-set images:', len(y_test))\n",
    "print(y_test)\n",
    "y_pred = np.round(np.reshape(a=y_pred, newshape=(1, -1)), decimals=2)[0]\n",
    "print(y_pred)\n",
    "y_pred_rnd = np.round(np.reshape(a=y_pred, newshape=(1, -1)))[0]\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred_rnd)\n",
    "print('confusion matrix:')\n",
    "print(cm)\n",
    "print('test-set accuracy:', (cm[0][0] + cm[1][1])/np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "M6EZuRLHgqrf",
    "outputId": "28dee469-75ab-47cc-a76f-9704d6625f8a"
   },
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "labels = ['normal', 'affected']\n",
    "h = sns.heatmap(data=cm, cmap='Blues', annot=annotations, annot_kws={'size': 15}, fmt='d',\n",
    "                vmin=0, vmax=150, xticklabels=labels, yticklabels=labels, cbar=False)\n",
    "h.set_yticklabels(h.get_yticklabels(), rotation=0)\n",
    "plt.title('annotated heatmap for confusion matrix')\n",
    "plt.show()\n",
    "# fig1.savefig('/content/drive/My Drive/cm_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mdd9GAo9INHb"
   },
   "outputs": [],
   "source": [
    "# save model config as json file\n",
    "model_json = classifier.to_json()\n",
    "with open(\"/content/drive/My Drive/COVID-CXNet_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TpLgn07gT8Kz"
   },
   "source": [
    "## Heatmap generation for sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "iUotCuxQsAb-",
    "outputId": "d82f34b4-e723-49d8-d11e-da87cf41a2d8"
   },
   "outputs": [],
   "source": [
    "predictor = load_model('/content/drive/My Drive/COVID-CXNet_model.hdf5')\n",
    "predictor = classifier\n",
    "IMG_ID = np.random.randint(low=0, high=len(X), size=None)\n",
    "# IMG_ID = ?\n",
    "print('image index:', IMG_ID)\n",
    "\n",
    "# test_img = np.zeros(shape=(600, 600, 3))\n",
    "# test_img[140:460, 140:460] = X[IMG_ID]\n",
    "# test_img = cv2.resize(src=test_img, dsize=(320, 320))\n",
    "\n",
    "test_img = X[IMG_ID]\n",
    "temp_img = (test_img * 255.).astype('uint8')\n",
    "\n",
    "\n",
    "cam = GradCAM(model=predictor, classIdx=0, layerName=None)\n",
    "heatmap = cam.compute_heatmap(image=test_img, normalize=True)\n",
    "overlaid_heatmap = cam.overlay_heatmap(heatmap=heatmap, image=temp_img, alpha=0.8, \n",
    "                                       colormap=cv2.COLORMAP_HSV)\n",
    "\n",
    "# overlaid_heatmap = overlaid_heatmap[75:245, 75:245, :]\n",
    "# test_img = test_img[75:245, 75:245]\n",
    "\n",
    "fig = plt.figure(num=2, figsize=(8, 16))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(overlaid_heatmap)\n",
    "plt.axis('off')\n",
    "plt.title('pred=%.4f' % predictor.predict(np.expand_dims(test_img, axis=0)))\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(test_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('label=%d' % y[IMG_ID])\n",
    "plt.show()\n",
    "# fig.savefig('/content/drive/My Drive/f_%d.jpg' % IMG_ID, bbox_inches='tight', pad_inches=0.1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMbW5x223BybpjXmZoORk3u",
   "include_colab_link": true,
   "machine_shape": "hm",
   "mount_file_id": "1D1UE47UxMYqPV4O1wLO1NqpB2yRoUp_2",
   "name": "hands_on_covid_cxnet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
